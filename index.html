<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧</title>
  <meta name="author" content="John Doe">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-70812759-1', 'auto');
  ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?cb5448498d7169c668b07c2b255d62c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class=""></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class=""></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/Tags" title="All the tags.">
			  <i class=""></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/About" title="About me.">
			  <i class=""></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <div class="page-header logo">
  <h1>Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧<span class="blink-fast">∎</span></h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">
      <i class="fa fa-heart blink-slow"></i>
      What are you waiting for!
</div>    
		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2018/06/06/scarpy初探/" title="scrapy项目简单尝试-----&gt; &lt;a href=&#34;&#34; onclick=&#34;alert(&#39;o(￣ヘ￣o#)都说了让你不要点&#39;)&#34;&gt;请不要点击此处&lt;/a&gt;">scarpy初探</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2018-06-06  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h1 id="scrapy-使用初探"><a href="#scrapy-使用初探" class="headerlink" title="scrapy 使用初探"></a>scrapy 使用初探</h1><h2 id="what-is-scrapy？"><a href="#what-is-scrapy？" class="headerlink" title="what is scrapy？"></a>what is scrapy？</h2><p>【摘自scrapy中文文档】Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。<br>其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。<br>当然，常用的python爬虫框架还有狠毒，比如pyspider，它会提供一个机遇浏览器的编辑页面，适于快速创建爬虫，但是好像是主要使用与linux（mac的），有兴趣的可以自己去查下相关的资料。</p>
<p>##目标<br>这篇blog主要是为了大致记录一下基础的scrapy的流程和部分记录下一些有用的小知识点，所以整体不会太过详细，偏流程便于自己看。<br>功能很简答，通过excel提供的cve编号爬取参考链接，参考链接的来源的这里采用cve的，当然也可以是NVD，但是最近好像NVD的网站不是很稳定，所以未采用，整体功能还是比较简单的（对我就是这么菜,请不要嘲笑我的代码✧(≖ ◡ ≖✿)嘿嘿）。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><pre><code>- 创建爬虫
- 编写spider
- 输出结果
</code></pre><h3 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h3><p>首先，scrapy对于python3和python2都有对应的兼容，但是为了区别创建的项目是py3还是py2的，可以采用在命令行里输入<code>python3/2 -m scrapy startproject #your project name#</code>【当然前提是已经安装好了scrapy】,随后会在当前目录下创建一个你命名的文件夹（这里我们就命名为cve好了）其大致的目录结构是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg</span><br><span class="line">cve/</span><br><span class="line">    __init__.py</span><br><span class="line">    items.py</span><br><span class="line">    pipelines.py</span><br><span class="line">    settings.py</span><br><span class="line">    spiders/</span><br><span class="line">        __init__.py</span><br><span class="line">        ......</span><br></pre></td></tr></table></figure>
<h2 id="编写爬虫"><a href="#编写爬虫" class="headerlink" title="编写爬虫"></a>编写爬虫</h2><p>当基本的项目创建完之后，需要在spider目录下新建一个spider.py文件编写spider（当然名字可以自取），然后添加巨日的爬虫代码，这里我们简要分析我我们的需求</p>
<pre><code>- 需要解析excel获取cve编号
- 解析爬取到的网页，获取参考链接
</code></pre><ol>
<li>解析excel获取cve编号<br>首先需要获取excel汇总的cve编号，然后编成需要爬去的url，由于是多url爬去，最粗暴的方式就是直接生成多个start_url然后进行爬取start_url是scrapy爬虫的url获取的入口），此处由于没有别的过多的要求，所以可以采用最粗暴的方式直接生成list：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    allowed_domains = [&apos;cve.mitre.org&apos;]</span><br><span class="line">    filename = r&apos;1.xlsx&apos;</span><br><span class="line">    try:</span><br><span class="line">        book = xlrd.open_workbook(filename)</span><br><span class="line">        sheet0 = book.sheet_by_index(0)</span><br><span class="line">        start_urls = [&apos;http://cve.mitre.org/cgi-bin/cvename.cgi?name=&apos;+cve for cve in sheet0.col_values(0)]</span><br><span class="line">        # for url in start_urls:</span><br><span class="line">        #     print(&apos;\033[1;32;m&apos;)</span><br><span class="line">        #     print(url)</span><br><span class="line">        #     print(&apos;\033[0m&apos;)</span><br><span class="line">    except ImportError as execlerror1:</span><br><span class="line">        print(&apos;\033[1;33;m&apos;)</span><br><span class="line">        print(&apos;While read the excel error!!! ERROR:%s&apos;%execlerror1)</span><br><span class="line">        print(&apos;\033[0m&apos;)</span><br><span class="line">```</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>解析爬取到的网页<br>这里采用的是xpath的方式获取，建议可以在chrome中装个xpath插件测试过程我就不多说了,这里需要提前设置下，scrapy可以把需要获取的内容设置在item里，这里我们设置成url，用jion()方法是为了多个参考链接时用“，”间隔:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">```def parse(self, response):</span><br><span class="line">        selector = Selector(response)</span><br><span class="line">        item = CveItem()</span><br><span class="line">        try:</span><br><span class="line">            table = selector.xpath(&apos;/html&apos;)</span><br><span class="line">            for each in table:</span><br><span class="line">                item[&apos;url&apos;] = &quot;,&quot;.join(each.xpath(&apos;//li/a/@href&apos;).extract())</span><br><span class="line">                # print(type(item[&apos;url&apos;]))</span><br><span class="line">                yield item</span><br><span class="line">        except ImportError as xpatherrro:</span><br><span class="line">            print(&apos;\033[1;33;m&apos;)</span><br><span class="line">            print(&apos;Xpath error!!! ERROR:%s&apos;%xpatherrro)</span><br><span class="line">            print(&apos;\033[0m&apos;)</span><br><span class="line">        print(item[&apos;url&apos;])</span><br></pre></td></tr></table></figure>
</li>
<li><p>调试<br>当然，我们编辑爬虫一般会在编辑器中进行编辑，比如pycharm，我们可以设置相关目录，为了方便编辑，我们需要在项目的目录下（也就是最外层的cve目录下）创建一个文件，这里我们命名为entrypoint.py，然后添加：</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.cmdline import execute</span><br><span class="line">execute([&apos;scrapy&apos;, &apos;crawl&apos;, &apos;cvedemo&apos;])</span><br></pre></td></tr></table></figure>
<p>然后在pycharm中设置配置，script设置为该文件，可以参考这篇blog: <a href="https://blog.csdn.net/u012052268/article/details/72063917" target="_blank" rel="noopener">https://blog.csdn.net/u012052268/article/details/72063917</a></p>
<h2 id="输出结果（包括参数设置）"><a href="#输出结果（包括参数设置）" class="headerlink" title="输出结果（包括参数设置）"></a>输出结果（包括参数设置）</h2><p>首先有几个参数需要设置好<br>items.py需要设置需要的要输出的变量，本文中设置为<code>url = scrapy.Field()</code><br>另外还有一个问题，就是scrapy是异步多线程的，会导致一个结果，就是结果输出的顺序和start_url的顺序不一致，其实可以有多种方式处理，这里因为没有时间限制，所以我采用了最简单的方法，改并发设为<code>CONCURRENT_REQUESTS = 1</code>，这种方法比较简单代码量也相对较少但是时间会较长,当然解决方式还有别的办法，比如可以输出两个结果，cve编号和参考链接量列内容，虽然顺序可能回稍微变动，但是速度会快很多。<br>结果输出这块，需要修改piplines.py，scrapy输出的方式有很多种，也可以通过命令导出为csv文件，这里由于只要一列输出，可以直接导出到txt上，最方便。</p>
<figure class="highlight plain"><figcaption><span>process_item(self, item, spider):</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 以追加的方式打开文件，不存在则创建</span><br><span class="line"># 因为item中的数据是unicode编码，为了在控制台中查看数据的有效性和保存，</span><br><span class="line"># 将其编码改为utf-8</span><br><span class="line">with open(&apos;res.txt&apos;, &apos;a&apos;) as f:</span><br><span class="line">    f.write(item[&apos;url&apos;] + &apos;\n&apos;)</span><br><span class="line">return item</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇blog写的比较简单，更注重流程一些，还有几个基础的点，时间比较有限，所以没有写的很详细，主要便于自己温习用的，代码我传到了github，代码非常基础，可以当做一个简单的入门了解，项目链接<a href="https://github.com/hushpuppy00/cve" target="_blank" rel="noopener">https://github.com/hushpuppy00/cve</a></p>

	
	</div>
  <a type="button" href="/2018/06/06/scarpy初探/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2018/05/21/hello-world/" >Hello World</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2018-05-21  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

	
	</div>
  <a type="button" href="/2018/05/21/hello-world/#more" class="btn btn-default more">Read More</a>
</div>

		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">

   
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
	<div class="widget">
		<h4>Categories</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/categories/python-scrapy/">python-scrapy<span>1</span></a></li>
		
		</ul>
	</div>

		
			
	<div class="widget">
		<h4>Tag Cloud</h4>
		<ul class="tag_box inline list-unstyled">		
		
			<li><a href="/tags/python-scrapy/">python scrapy<span>1</span></a></li>
		
		 
		</ul>
	</div>


		
			
<div class="widget">
  <h4>Recent Posts</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2018/06/06/scarpy初探/"  title="scrapy项目简单尝试-----&gt; &lt;a href=&#34;&#34; onclick=&#34;alert(&#39;o(￣ヘ￣o#)都说了让你不要点&#39;)&#34;&gt;请不要点击此处&lt;/a&gt;" ><i class="fa fa-file-o"></i>scarpy初探</a>
      </li>
    
      <li>
        <a href="/2018/05/21/hello-world/" ><i class="fa fa-file-o"></i>Hello World</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/hushpuppy00" title="My Github account." target="_blank"]);">My Github</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->
	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2018 John Doe
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a>,<a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>,<a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a> and <a href="http://getbootstrap.com/" target="_blank">BOOTSTRA.386</a>. 
     <br> Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind.386</a>.    
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
