<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>scarpy初探 | Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧</title>
  <meta name="author" content="John Doe">
  
  <meta name="description" content="scrapy项目简单尝试-----&gt; &lt;a href=&#34;&#34; onclick=&#34;alert(&#39;o(￣ヘ￣o#)都说了让你不要点&#39;)&#34;&gt;请不要点击此处&lt;/a&gt;">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="scarpy初探"/>
  <meta property="og:site_name" content="Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-70812759-1', 'auto');
  ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?cb5448498d7169c668b07c2b255d62c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Hushpuppy&#39;s Blog (๑•̀ㅂ•́)و✧</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class=""></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class=""></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/Tags" title="All the tags.">
			  <i class=""></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/About" title="About me.">
			  <i class=""></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">
			<h1> scarpy初探</h1>
		</div>
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  
		 <div class="alert alert-success description">
			<i class="fa fa-info-circle"></i> scrapy项目简单尝试-----> <a href="" onclick="alert('o(￣ヘ￣o#)都说了让你不要点')">请不要点击此处</a>
		 </div> <!-- alert -->
	  		

	  <h1 id="scrapy-使用初探"><a href="#scrapy-使用初探" class="headerlink" title="scrapy 使用初探"></a>scrapy 使用初探</h1><h2 id="what-is-scrapy？"><a href="#what-is-scrapy？" class="headerlink" title="what is scrapy？"></a>what is scrapy？</h2><p>【摘自scrapy中文文档】Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。<br>其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。<br>当然，常用的python爬虫框架还有狠毒，比如pyspider，它会提供一个机遇浏览器的编辑页面，适于快速创建爬虫，但是好像是主要使用与linux（mac的），有兴趣的可以自己去查下相关的资料。</p>
<p>##目标<br>这篇blog主要是为了大致记录一下基础的scrapy的流程和部分记录下一些有用的小知识点，所以整体不会太过详细，偏流程便于自己看。<br>功能很简答，通过excel提供的cve编号爬取参考链接，参考链接的来源的这里采用cve的，当然也可以是NVD，但是最近好像NVD的网站不是很稳定，所以未采用，整体功能还是比较简单的（对我就是这么菜,请不要嘲笑我的代码✧(≖ ◡ ≖✿)嘿嘿）。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><pre><code>- 创建爬虫
- 编写spider
- 输出结果
</code></pre><h3 id="创建爬虫"><a href="#创建爬虫" class="headerlink" title="创建爬虫"></a>创建爬虫</h3><p>首先，scrapy对于python3和python2都有对应的兼容，但是为了区别创建的项目是py3还是py2的，可以采用在命令行里输入<code>python3/2 -m scrapy startproject #your project name#</code>【当然前提是已经安装好了scrapy】,随后会在当前目录下创建一个你命名的文件夹（这里我们就命名为cve好了）其大致的目录结构是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg</span><br><span class="line">cve/</span><br><span class="line">    __init__.py</span><br><span class="line">    items.py</span><br><span class="line">    pipelines.py</span><br><span class="line">    settings.py</span><br><span class="line">    spiders/</span><br><span class="line">        __init__.py</span><br><span class="line">        ......</span><br></pre></td></tr></table></figure>
<h2 id="编写爬虫"><a href="#编写爬虫" class="headerlink" title="编写爬虫"></a>编写爬虫</h2><p>当基本的项目创建完之后，需要在spider目录下新建一个spider.py文件编写spider（当然名字可以自取），然后添加巨日的爬虫代码，这里我们简要分析我我们的需求</p>
<pre><code>- 需要解析excel获取cve编号
- 解析爬取到的网页，获取参考链接
</code></pre><ol>
<li>解析excel获取cve编号<br>首先需要获取excel汇总的cve编号，然后编成需要爬去的url，由于是多url爬去，最粗暴的方式就是直接生成多个start_url然后进行爬取start_url是scrapy爬虫的url获取的入口），此处由于没有别的过多的要求，所以可以采用最粗暴的方式直接生成list：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    allowed_domains = [&apos;cve.mitre.org&apos;]</span><br><span class="line">    filename = r&apos;1.xlsx&apos;</span><br><span class="line">    try:</span><br><span class="line">        book = xlrd.open_workbook(filename)</span><br><span class="line">        sheet0 = book.sheet_by_index(0)</span><br><span class="line">        start_urls = [&apos;http://cve.mitre.org/cgi-bin/cvename.cgi?name=&apos;+cve for cve in sheet0.col_values(0)]</span><br><span class="line">        # for url in start_urls:</span><br><span class="line">        #     print(&apos;\033[1;32;m&apos;)</span><br><span class="line">        #     print(url)</span><br><span class="line">        #     print(&apos;\033[0m&apos;)</span><br><span class="line">    except ImportError as execlerror1:</span><br><span class="line">        print(&apos;\033[1;33;m&apos;)</span><br><span class="line">        print(&apos;While read the excel error!!! ERROR:%s&apos;%execlerror1)</span><br><span class="line">        print(&apos;\033[0m&apos;)</span><br><span class="line">```</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>解析爬取到的网页<br>这里采用的是xpath的方式获取，建议可以在chrome中装个xpath插件测试过程我就不多说了,这里需要提前设置下，scrapy可以把需要获取的内容设置在item里，这里我们设置成url，用jion()方法是为了多个参考链接时用“，”间隔:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">```def parse(self, response):</span><br><span class="line">        selector = Selector(response)</span><br><span class="line">        item = CveItem()</span><br><span class="line">        try:</span><br><span class="line">            table = selector.xpath(&apos;/html&apos;)</span><br><span class="line">            for each in table:</span><br><span class="line">                item[&apos;url&apos;] = &quot;,&quot;.join(each.xpath(&apos;//li/a/@href&apos;).extract())</span><br><span class="line">                # print(type(item[&apos;url&apos;]))</span><br><span class="line">                yield item</span><br><span class="line">        except ImportError as xpatherrro:</span><br><span class="line">            print(&apos;\033[1;33;m&apos;)</span><br><span class="line">            print(&apos;Xpath error!!! ERROR:%s&apos;%xpatherrro)</span><br><span class="line">            print(&apos;\033[0m&apos;)</span><br><span class="line">        print(item[&apos;url&apos;])</span><br></pre></td></tr></table></figure>
</li>
<li><p>调试<br>当然，我们编辑爬虫一般会在编辑器中进行编辑，比如pycharm，我们可以设置相关目录，为了方便编辑，我们需要在项目的目录下（也就是最外层的cve目录下）创建一个文件，这里我们命名为entrypoint.py，然后添加：</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.cmdline import execute</span><br><span class="line">execute([&apos;scrapy&apos;, &apos;crawl&apos;, &apos;cvedemo&apos;])</span><br></pre></td></tr></table></figure>
<p>然后在pycharm中设置配置，script设置为该文件，可以参考这篇blog: <a href="https://blog.csdn.net/u012052268/article/details/72063917" target="_blank" rel="noopener">https://blog.csdn.net/u012052268/article/details/72063917</a></p>
<h2 id="输出结果（包括参数设置）"><a href="#输出结果（包括参数设置）" class="headerlink" title="输出结果（包括参数设置）"></a>输出结果（包括参数设置）</h2><p>首先有几个参数需要设置好<br>items.py需要设置需要的要输出的变量，本文中设置为<code>url = scrapy.Field()</code><br>另外还有一个问题，就是scrapy是异步多线程的，会导致一个结果，就是结果输出的顺序和start_url的顺序不一致，其实可以有多种方式处理，这里因为没有时间限制，所以我采用了最简单的方法，改并发设为<code>CONCURRENT_REQUESTS = 1</code>，这种方法比较简单代码量也相对较少但是时间会较长,当然解决方式还有别的办法，比如可以输出两个结果，cve编号和参考链接量列内容，虽然顺序可能回稍微变动，但是速度会快很多。<br>结果输出这块，需要修改piplines.py，scrapy输出的方式有很多种，也可以通过命令导出为csv文件，这里由于只要一列输出，可以直接导出到txt上，最方便。</p>
<figure class="highlight plain"><figcaption><span>process_item(self, item, spider):</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 以追加的方式打开文件，不存在则创建</span><br><span class="line"># 因为item中的数据是unicode编码，为了在控制台中查看数据的有效性和保存，</span><br><span class="line"># 将其编码改为utf-8</span><br><span class="line">with open(&apos;res.txt&apos;, &apos;a&apos;) as f:</span><br><span class="line">    f.write(item[&apos;url&apos;] + &apos;\n&apos;)</span><br><span class="line">return item</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇blog写的比较简单，更注重流程一些，还有几个基础的点，时间比较有限，所以没有写的很详细，主要便于自己温习用的，代码我传到了github，代码非常基础，可以当做一个简单的入门了解，项目链接<a href="https://github.com/hushpuppy00/cve" target="_blank" rel="noopener">https://github.com/hushpuppy00/cve</a></p>
	  
	</div>

	<div>
  	<center>
	<div class="pagination">

    
    
    <a type="button" class="btn btn-default disabled"><i class="fa fa-arrow-circle-o-left"></i>Prev</a>
    

    <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
    
    <a href="/2018/05/21/hello-world/" type="button" class="btn btn-default ">Next<i
                class="fa fa-arrow-circle-o-right"></i></a>
    

    
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">
    <h2 class="title">Comments</h2>

    
</section>


	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2018-06-06 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/python-scrapy/">python-scrapy<span>1</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/python-scrapy/">python scrapy<span>1</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2018 John Doe
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a>,<a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>,<a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a> and <a href="http://getbootstrap.com/" target="_blank">BOOTSTRA.386</a>. 
     <br> Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind.386</a>.    
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
